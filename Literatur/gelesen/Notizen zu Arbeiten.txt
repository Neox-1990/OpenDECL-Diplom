A Survey of Large High Resolution Display Technologies, Techniques and Application 2006

Guter Hardwareüberblick -> Cave (Brille,Headtrack,Controler,6 DOF), Multi-Monitor-Desktop (Brezel-Problem), LCD Kacheln / Tabletop (Array -> günstig, Farbkorrektur einfacher, weniger Platz, einfach Auszurichten), Projektor-Array (verschiedene Typen v. Projektoren -> verschieden Anforderungen, braucht Platz, Rahmenlos, Größe variabel), Stereo-Displays (2x soviel Pixel, Headtracking), Volumentrische Displays (exot)

Render & Streaming -> Cluster mit Netzwerkanbindung (Videostream, Raytracing, Volumentrisch Rendern, ...), Unterscheidung Display Data Streaming + Distributed Rendering
Datastreaming:
a) Client-Server: Client kontaktiert nur Server, Server kommuniziert mit Cluster (transparent da wie eine Maschine aber großes Datenaufkommen im Netzwerk)
b) Master-Slave: Auf allen Nodes läuft gleiche Anwendung -> kommunikation und synchronisierung werden von Master übernommen (geringe Bandbreite aber schwer vorhersagbar)

Es werden verschiedene Softwarepakete angesprochen: Data Streaming Software, Distributed Render Software, Anwendungen

==> Interesanter Einstieg, auf jeden Fall Quellen weiter verfolgen bezüglich Aufbau, Kallibrierung und weiteres

======================

Position-Independent Interaction for LHRD 2007

Problemstellung: Maussteuerung für LHRD schwierig wenn man na dran ist -> flexibilität und bewegungsfreiheit, Maus und Tastatur brauchen Untergrund
Idee: Laserpointer als Maus-Tracking-Device
Umsetzung: Library für mehrere Kameras die sich selbst auf LHRD kalibrieren mit entsprechenden Kalibrierungsbilder. Kameras mit hohen FPS damit interaktionszeit-verzögerung nicht zu groß wird und Nutzer gutes Gefühl haben. Für R/G/B und IR Laser. IR Laser am besten, damit diskrepanz zwischen Laserpunkt und Maus nicht verwirrt. Aus Kameras Graustufenbild -> Punktgwicht -> auch mit geringerer Kameraauflösung gut machbar.
Evaluierung: Bei geringer Distanz ähnlich gut, aber immer noch schlechter als Maus, bei größerer Distanz noch ein wenig mehr hinter Maus-Performance, da Zittern größere Auswirkung hat. Aber Bewegungsfreiheit könnte Argument dafür sein.

==> Eher ein MCI-Paper, weniger für meine Aufgabe

======================

Designing LHRD Workspaces 2012

Untersuchung wie man einen LHRD-Workspace für alltägliche Aufgaben einrichten muss, bzw auf was man achten muss. Geschah anhand Probanden die dies über 18 Monate probiert haben. See it all effekt vs physikalische Navigation.

Faktoren: Höhe des Displays, Krümmung, Halterung, Tastatur und Mausposition, Nutzerposition.

Empfehlung: Hufeisenkrümmung, variable Krümmung für Collaboration, Halterung auf Tisch, Kopfposition gleich weit von allen Bildschirmen entfernt, Normaler Bürostuhl mit mobilität, Maus und Tastatur an Armlehne

==> Hatte gehofft mehr über die eigentliche Installation und Kalibrierung zu erfahren, aber mehr ein MCI bzw Ergonomie Paper

======================

FlowVR: a middleware for large scale virtual realtity applications 2004

VR-Middleware für Cluster

Problem -> skalierung, verschiedene updateraten / Frequenzen

FlowVR-> middleware, möglichst wenige Änderungen zu bestehenden Code, timing, synchronisierung, für komplexe Kommunikation im Cluster

Applicationmodel: Nodes mit Input und Output-Ports -> Module die verschiedene Aufgaben übernehmen Bspw: Berechnungen/Simulationen, Visualisierung / Teilvisualisierung, Synchronisierung / Filterung
Weiterer wichtiger Punkt -> Connection (FIFO-Channels): zwischen den Ports, stemps als ID und Iterations Parameter, routing-nodes zum verteilen und aufsplitten von Connection (Outputs)

Besonders Interessant: XML-Description of the FlowVR Network -> Alle Komponenten auf Nodes

==> Hat mein Verständniss von Distributed/Parallel Computing in Cluster erhöht. Leider kein Hardwarebezug bzgl. Displays, jedoch interessant bzgl. Netzwerkbeschreibung, sogar als XML

======================

Chromium: A Stream-processing Framework for Interactive Rendering on Clusters 2002

Architektur: Auf Basis von WireGL -> ClusterNodes = Computer in Cluster, Kanten sind Netzwerkverbindungen/Traffic, jeder Node hat zwei Teile: 1. transformation->nimmt einen Stream(OpenGL-COmmands) und kann auf >0 Outputstreams verteilen/mappen. 2. Serialisierung -> >1 Inputs Stream und nur 1 Outputstream -> Servernode, wenn kein Input aber 1 Output -> Clientnode

bzgl transforming: OpenGL Stream Processing Unit (SPU) mit verschiedenen Funktionen -> Jeder Node läd sich seine Lib für die SPU

Tools: packing und unpacking von Streams, Netzwerkabstraktion (TCP/IP) -> möglicher Seitenkanal zu kommunikation zwischen SPUs, OpenGL-State-Tracker -> vergleicht zwei Grafik-Kontexte, + jede Menge weitere SPUs/Funktionen.

Bsp. 3.6 (S.4)

4.1 Beispiel Volumenrender
4.2 Beispiel Darstellen auf einem (großen) Bildschirm mit SGE wo im Cluster gerendert wurde
4.3 Beispiel stylized rendering mit Quake3 als Ausgang

==> Weiterer Interessanter Einblick ins Cluster-Computing -> Cluster Stream Processing -> Middleware zum steuern von API-Commands, paralleles render, leider kein Hardwarebezug, semiinteressant aber mal gelesen weil sehr oft zitiert.